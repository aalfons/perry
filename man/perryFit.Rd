\name{perryFit}
\alias{perryFit}
\alias{perryFit.call}
\alias{perryFit.default}
\alias{perryFit.function}
\alias{print.perry}
\title{Resampling-based prediction error for model evaluation}
\usage{
  perryFit(object, ...)

  \method{perryFit}{default} (object, data = NULL,
    x = NULL, y, splits = foldControl(),
    predictFun = predict, predictArgs = list(),
    cost = rmspe, costArgs = list(), names = NULL,
    envir = parent.frame(), ncores = 1, cl = NULL,
    seed = NULL, ...)

  \method{perryFit}{function} (object, formula,
    data = NULL, x = NULL, y, args = list(),
    splits = foldControl(), predictFun = predict,
    predictArgs = list(), cost = rmspe, costArgs = list(),
    names = NULL, envir = parent.frame(), ncores = 1,
    cl = NULL, seed = NULL, ...)

  \method{perryFit}{call} (object, data = NULL, x = NULL,
    y, splits = foldControl(), predictFun = predict,
    predictArgs = list(), cost = rmspe, costArgs = list(),
    names = NULL, envir = parent.frame(), ncores = 1,
    cl = NULL, seed = NULL, ...)
}
\arguments{
  \item{object}{the fitted model for which to estimate the
  prediction error, a function for fitting a model, or an
  unevaluated function call for fitting a model (see
  \code{\link{call}} for the latter).  In the case of a
  fitted model, the object is required to contain a
  component \code{call} that stores the function call used
  to fit the model, which is typically the case for objects
  returned by model fitting functions.}

  \item{formula}{a \code{\link[stats]{formula}} describing
  the model.}

  \item{data}{a data frame containing the variables
  required for fitting the models.  This is typically used
  if the model in the function call is described by a
  \code{\link[stats]{formula}}.}

  \item{x}{a numeric matrix containing the predictor
  variables.  This is typically used if the function call
  for fitting the models requires the predictor matrix and
  the response to be supplied as separate arguments.}

  \item{y}{a numeric vector or matrix containing the
  response.}

  \item{args}{a list of additional arguments to be passed
  to the model fitting function.}

  \item{splits}{an object of class \code{"cvFolds"} (as
  returned by \code{\link{cvFolds}}) or a control object of
  class \code{"foldControl"} (see
  \code{\link{foldControl}}) defining the folds of the data
  for (repeated) \eqn{K}-fold cross-validation, an object
  of class \code{"randomSplits"} (as returned by
  \code{\link{randomSplits}}) or a control object of class
  \code{"splitControl"} (see \code{\link{splitControl}})
  defining random data splits, or an object of class
  \code{"bootSamples"} (as returned by
  \code{\link{bootSamples}}) or a control object of class
  \code{"bootControl"} (see \code{\link{bootControl}})
  defining bootstrap samples.}

  \item{predictFun}{a function to compute predictions for
  the test data.  It should expect the fitted model to be
  passed as the first argument and the test data as the
  second argument, and must return either a vector or a
  matrix containing the predicted values.  The default is
  to use the \code{\link[stats]{predict}} method of the
  fitted model.}

  \item{predictArgs}{a list of additional arguments to be
  passed to \code{predictFun}.}

  \item{cost}{a cost function measuring prediction loss.
  It should expect the observed values of the response to
  be passed as the first argument and the predicted values
  as the second argument, and must return either a
  non-negative scalar value, or a list with the first
  component containing the prediction error and the second
  component containing the standard error.  The default is
  to use the root mean squared prediction error (see
  \code{\link{cost}}).}

  \item{costArgs}{a list of additional arguments to be
  passed to the prediction loss function \code{cost}.}

  \item{names}{an optional character vector giving names
  for the arguments containing the data to be used in the
  function call (see \dQuote{Details}).}

  \item{envir}{the \code{\link{environment}} in which to
  evaluate the function call for fitting the models (see
  \code{\link{eval}}).}

  \item{ncores}{a positive integer giving the number of
  processor cores to be used for parallel computing (the
  default is 1 for no parallelization).  If this is set to
  \code{NA}, all available processor cores are used.}

  \item{cl}{a \pkg{parallel} cluster for parallel computing
  as generated by \code{\link[parallel]{makeCluster}}.
  This is ignored if \code{ncores} is supplied.}

  \item{seed}{optional initial seed for the random number
  generator (see \code{\link{.Random.seed}}).  Note that
  also in case of parallel computing, resampling is
  performed on the manager process rather than the worker
  processes. On the parallel worker processes, random
  number streams are always set for reproducibility in case
  the model fitting function involves randomness (see
  \code{\link{clusterSetRNGStream}}).}

  \item{\dots}{additional arguments to be passed down.}
}
\value{
  An object of class \code{"perry"} with the following
  components:

  \item{pe}{a numeric vector containing the respective
  estimated prediction errors.  In case of more than one
  replication, those are average values over all
  replications.}

  \item{se}{a numeric vector containing the respective
  estimated standard errors of the prediction loss.}

  \item{reps}{a numeric matrix in which each column
  contains the respective estimated prediction errors from
  all replications.  This is only returned in case of more
  than one replication.}

  \item{splits}{an object giving the data splits used to
  estimate the prediction error.}

  \item{y}{the response.}

  \item{yHat}{a list containing the predicted values from
  all replications.}

  \item{seed}{the seed of the random number generator
  before estimation of the prediction error.}

  \item{call}{the matched function call.}
}
\description{
  Estimate the prediction error of a model via (repeated)
  \eqn{K}-fold cross-validation, (repeated) random
  splitting (also known as random subsampling or Monte
  Carlo cross-validation), or the bootstrap.  It is thereby
  possible to supply an object returned by a model fitting
  function, a model fitting function itself, or an
  unevaluated function call to a model fitting function.
}
\details{
  (Repeated) \eqn{K}-fold cross-validation is performed in
  the following way.  The data are first split into \eqn{K}
  previously obtained blocks of approximately equal size
  (given by \code{folds}).  Each of the \eqn{K} data blocks
  is left out once to fit the model, and predictions are
  computed for the observations in the left-out block with
  \code{predictFun}.  Thus a prediction is obtained for
  each observation.  The response variable and the obtained
  predictions for all observations are then passed to the
  prediction loss function \code{cost} to estimate the
  prediction error.  For repeated \eqn{K}-fold
  cross-validation (as indicated by \code{splits}), this
  process is replicated and the estimated prediction errors
  from all replications are returned.

  (Repeated) random splitting is performed similarly.  In
  each replication, the data are split into a training set
  and a test set at random.  Then the training data is used
  to fit the model, and predictions are computed for the
  test data.  Hence only the response values from the test
  data and the corresponding predictions are passed to the
  prediction loss function \code{cost}.

  For the bootstrap estimator, each bootstrap sample is
  used as training data to fit the model.  The out-of-bag
  estimator uses the observations that do not enter the
  bootstrap sample as test data and computes the prediction
  loss function \code{cost} for those out-of-bag
  observations.  The 0.632 estimator is computed as a
  linear combination of the out-of-bag estimator and the
  prediction loss of the fitted values of the model
  computed from the full sample.

  In any case, if the response is a vector but
  \code{predictFun} returns a matrix, the prediction error
  is computed for each column.  A typical use case for this
  behavior would be if \code{predictFun} returns
  predictions from an initial model fit and stepwise
  improvements thereof.

  If \code{formula} or \code{data} are supplied, all
  variables required for fitting the models are added as
  one argument to the function call, which is the typical
  behavior of model fitting functions with a
  \code{\link[stats]{formula}} interface.  In this case,
  the accepted values for \code{names} depend on the
  method.  For the \code{function} method, a character
  vector of length two should supplied, with the first
  element specifying the argument name for the formula and
  the second element specifying the argument name for the
  data (the default is to use \code{c("formula", "data")}).
  Note that names for both arguments should be supplied
  even if only one is actually used.  For the other
  methods, which do not have a \code{formula} argument, a
  character string specifying the argument name for the
  data should be supplied (the default is to use
  \code{"data"}).

  If \code{x} is supplied, on the other hand, the predictor
  matrix and the response are added as separate arguments
  to the function call.  In this case, \code{names} should
  be a character vector of length two, with the first
  element specifying the argument name for the predictor
  matrix and the second element specifying the argument
  name for the response (the default is to use \code{c("x",
  "y")}).  It should be noted that the \code{formula} or
  \code{data} arguments take precedence over \code{x}.
}
\examples{
data("coleman")
set.seed(1234)  # set seed for reproducibility

## via model fit
# fit an MM regression model
fit <- lmrob(Y ~ ., data=coleman)
# perform cross-validation
perryFit(fit, data = coleman, y = coleman$Y, 
    splits = foldControl(K = 5, R = 10), 
    cost = rtmspe, costArgs = list(trim = 0.1), 
    seed = 1234)

## via model fitting function
# perform cross-validation
# note that the response is extracted from 'data' in 
# this example and does not have to be supplied
perryFit(lmrob, formula = Y ~ ., data = coleman, 
    splits = foldControl(K = 5, R = 10), 
    cost = rtmspe, costArgs = list(trim = 0.1), 
    seed = 1234)

## via function call
# set up function call
call <- call("lmrob", formula = Y ~ .)
# perform cross-validation
perryFit(call, data = coleman, y = coleman$Y, 
    splits = foldControl(K = 5, R = 10), 
    cost = rtmspe, costArgs = list(trim = 0.1), 
    seed = 1234)
}
\author{
  Andreas Alfons
}
\seealso{
  \code{\link{perrySelect}}, \code{\link{perryTuning}},
  \code{\link{cvFolds}}, \code{\link{randomSplits}},
  \code{\link{bootSamples}}, \code{\link{cost}}
}
\keyword{utilities}

